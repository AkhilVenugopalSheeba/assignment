{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6aRvzWzbhcnp"
   },
   "source": [
    "#Data Acquisition Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "734JDyUNq8fH"
   },
   "source": [
    "## Q1. Write Python code to create a new file named \"sample_data.txt\" in your documents folder and write the following content to it\n",
    "\n",
    "ICTAK\n",
    "\n",
    "Thejaswini,\n",
    "\n",
    "Technopark Rd,\n",
    "\n",
    "Technopark Campus,\n",
    "\n",
    "Thiruvananthapuram,\n",
    "\n",
    "Kerala 695581"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "ieKhqBr-nl7s"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "documents_folder = os.path.expanduser(\"C:\\\\Users\\\\AKHIL\\\\ICT DSA\")\n",
    "file_path= os.path.join(documents_folder,\"sample_data.txt\")\n",
    "\n",
    "content = \"\"\"ICTAK\n",
    "Thejaswini,\n",
    "Technopark Rd,\n",
    "Technopark Campus,\n",
    "Thiruvananthapuram,\n",
    "Kerala 695581\"\"\"\n",
    "\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(content)\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJ6hQOJpimNv"
   },
   "source": [
    "## Q2. Write Python code to read and print the contents in \"sample_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "id": "vRnilPQgnrPG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICTAK\n",
      "Thejaswini,\n",
      "Technopark Rd,\n",
      "Technopark Campus,\n",
      "Thiruvananthapuram,\n",
      "Kerala 695581\n"
     ]
    }
   ],
   "source": [
    "documents_folder = os.path.expanduser(\"C:\\\\Users\\\\AKHIL\\\\ICT DSA\")\n",
    "file_path= os.path.join(documents_folder,\"sample_data.txt\")\n",
    "with open(file_path,\"r\") as file:\n",
    "    content = file.read()\n",
    "print(content)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aHquDcErda-"
   },
   "source": [
    "## Q3. Write Python code to check if \"sample_data.txt\" exists in documents folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "vY5TEsxunsKh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 'sample_data.txt' exists in C:\\Users\\AKHIL\\ICT DSA.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "documents_folder = os.path.expanduser(\"C:\\\\Users\\\\AKHIL\\\\ICT DSA\")\n",
    "file_path = os.path.join(documents_folder, \"sample_data.txt\")\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"The file 'sample_data.txt' exists in {documents_folder}.\")\n",
    "else:\n",
    "    print(f\"The file 'sample_data.txt' does not exist in {documents_folder}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCWITkmopblI"
   },
   "source": [
    "## Q4: Save the following dataframe content to a CSV file (data.csv) in your downloads folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "r3THwBOGpP9F"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\"Id\": [1, 2, 3],\n",
    "        \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "        \"Subject\": [\"Science\", \"Maths\", \"History\"]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "Joc7XafnntaG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has been saved to C:\\Users\\AKHIL\\ICT DSA\\data.csv\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "downloads_folder = os.path.expanduser(\"C:\\\\Users\\\\AKHIL\\\\ICT DSA\")\n",
    "file_path = os.path.join(downloads_folder,\"data.csv\")\n",
    "\n",
    "df.to_csv(file_path, index= False)\n",
    "print(f\"Dataframe has been saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id     Name  Subject\n",
      "0   1    Alice  Science\n",
      "1   2      Bob    Maths\n",
      "2   3  Charlie  History\n"
     ]
    }
   ],
   "source": [
    "df_read = pd.read_csv(file_path)\n",
    "print(df_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VF0nJjGElq0A"
   },
   "source": [
    "## Q5: Save the above dataframe content to an Excel (data.xlsx, sheet name: Sheet1) file in your documents folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "id": "ZtOFb7ZJnu1m"
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join(documents_folder,\"data.xlsx\")\n",
    "\n",
    "df.to_excel(file_path,sheet_name= \"Sheet1\",index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "amF6kxMQmdgF"
   },
   "source": [
    "## Q6. Write code to get the list of files in your Downloads folder and save it to a CSV file name \"download_list.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "nVP86z3dnvwz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "downloads_folder =os.path.expanduser(\"C:\\\\Users\\\\AKHIL\\\\Downloads\")\n",
    "\n",
    "file =os.listdir(downloads_folder)\n",
    "df = pd.DataFrame({\"File Name\": file})\n",
    "\n",
    "csv_file_path = os.path.join(downloads_folder,\"download_list.csv\")\n",
    "\n",
    "df.to_csv(csv_file_path, index= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            File Name\n",
      "0                      (Bulk 1) Add a heading (1).zip\n",
      "1                          (Bulk 1) Add a heading.zip\n",
      "2                             00_descriptive_stat.txt\n",
      "3   2023_rolls-royce_phantom_sedan_base_fq_oem_10_...\n",
      "4   2023_rolls-royce_phantom_sedan_base_fq_oem_10_...\n",
      "..                                                ...\n",
      "85                     VSCodeUserSetup-x64-1.97.2.exe\n",
      "86               wavy-black-white-background edit.png\n",
      "87                    wavy-black-white-background.jpg\n",
      "88              wp1930710-liberty-walk-wallpapers.jpg\n",
      "89  [MCU] Sookshmadarshini (2024) Malayalam HQ HDR...\n",
      "\n",
      "[90 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "read = pd.read_csv(csv_file_path)\n",
    "print(read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vR7I4R5bnV2w"
   },
   "source": [
    "## Q7. Write Python code to save the contents of the given random_array variable as a numpy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "vHXYRxnDnJzA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "random_array = np.random.rand(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "id": "ihhSKJF9n3NP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "random_array = np.random.rand(10, 10)\n",
    "\n",
    "documents_folder= os.path.expanduser(\"C:\\\\Users\\\\AKHIL\\\\ICT DSA\")\n",
    "file_path = os.path.join(documents_folder,\"random_array.npy\")\n",
    "\n",
    "np.save(file_path,random_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7XfHgGAzNIl"
   },
   "source": [
    "## Q8. Write python code to save the contents of the above numpy file as text file named \"random.txt\" with a delimitter of \";\" to Documents folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "Du3LRbaKbpeg"
   },
   "outputs": [],
   "source": [
    "document_folder = os.path.expanduser(\"C:\\\\Users\\\\AKHIL\\\\ICT DSA\")\n",
    "npy_file_path = os.path.join(documents_folder,\"random_array.npy\")\n",
    "txt_file_path= os.path.join(documents_folder,\"random.txt\")\n",
    "\n",
    "random_array = np.load(npy_file_path)\n",
    "\n",
    "np.savetxt(txt_file_path,random_array,delimiter=\";\",fmt=\"%.2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJSaX0Rg151y"
   },
   "source": [
    "## Download and analyze Bike Sharing Dataset (hour.csv) for UCI Irvin Repository (https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset) and answer the following questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wt4mxq32U6H"
   },
   "source": [
    "## Q9. What is the size of the dataset? (Number of rows and columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "id": "Pj0I0JhF2EEg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly Data(hour.csv): 17379 rows × 17 columns\n",
      "Daily Data(day.csv): 731 rows × 16 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hour_data = pd.read_csv(\"C:\\\\Users\\\\AKHIL\\\\ICT DSA\\\\bike+sharing+dataset\\\\hour.csv\")\n",
    "day_data = pd.read_csv(\"C:\\\\Users\\\\AKHIL\\\\ICT DSA\\\\bike+sharing+dataset\\\\day.csv\") \n",
    "\n",
    "\n",
    "hour_shape = hour_data.shape\n",
    "day_shape = day_data.shape\n",
    "\n",
    "\n",
    "print(f\"Hourly Data(hour.csv): {hour_shape[0]} rows × {hour_shape[1]} columns\")\n",
    "print(f\"Daily Data(day.csv): {day_shape[0]} rows × {day_shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbDnC_i438m8"
   },
   "source": [
    "## Q10. What are the data types of each column?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "id": "_YJIqJEZ3-DC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instant         int64\n",
      "dteday         object\n",
      "season          int64\n",
      "yr              int64\n",
      "mnth            int64\n",
      "hr              int64\n",
      "holiday         int64\n",
      "weekday         int64\n",
      "workingday      int64\n",
      "weathersit      int64\n",
      "temp          float64\n",
      "atemp         float64\n",
      "hum           float64\n",
      "windspeed     float64\n",
      "casual          int64\n",
      "registered      int64\n",
      "cnt             int64\n",
      "dtype: object\n",
      "instant         int64\n",
      "dteday         object\n",
      "season          int64\n",
      "yr              int64\n",
      "mnth            int64\n",
      "holiday         int64\n",
      "weekday         int64\n",
      "workingday      int64\n",
      "weathersit      int64\n",
      "temp          float64\n",
      "atemp         float64\n",
      "hum           float64\n",
      "windspeed     float64\n",
      "casual          int64\n",
      "registered      int64\n",
      "cnt             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(hour_data.dtypes)\n",
    "print(day_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zi0jHMq-3_NI"
   },
   "source": [
    "## Q11. Are there any missing values in the dataset? If so, which columns have missing values and how many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "id": "mct7F2M-3-kQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hour missing values\n",
      "Series([], dtype: int64)\n",
      "Day misssing values\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "hour = hour_data.isnull().sum()\n",
    "day = day_data.isnull().sum()\n",
    "\n",
    "print (\"Hour missing values\")\n",
    "print(hour[hour >0])\n",
    "print(\"Day misssing values\")\n",
    "print(day[day >0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ew__56Iq4BMK"
   },
   "source": [
    "## Q.12. For the windspeed column, calculate the mean, median, and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "id": "ucijLTNA4Clr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windspeed  Hour data\n",
      "Mean: 0.1901\n",
      "Median: 0.1940\n",
      "Standard Deviation: 0.1223\n",
      "wind speed of Day data\n",
      "Mean: 0.1905\n",
      "Median: 0.1810\n",
      "Standard Deviation: 0.0775\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hour_data = pd.read_csv(\"C:\\\\Users\\\\AKHIL\\\\ICT DSA\\\\bike+sharing+dataset\\\\hour.csv\")\n",
    "day_data = pd.read_csv(\"C:\\\\Users\\\\AKHIL\\\\ICT DSA\\\\bike+sharing+dataset\\\\day.csv\") \n",
    "\n",
    "hmean = hour_data[\"windspeed\"].mean()\n",
    "hmedian = hour_data[\"windspeed\"].median()\n",
    "hstd = hour_data[\"windspeed\"].std()\n",
    "\n",
    "\n",
    "dmean = day_data[\"windspeed\"].mean()\n",
    "dmedian = day_data[\"windspeed\"].median()\n",
    "dstd = day_data[\"windspeed\"].std()\n",
    "\n",
    "print(f\"Windspeed  Hour data\")\n",
    "print(f\"Mean: {hmean:.4f}\")\n",
    "print(f\"Median: {hmedian:.4f}\")\n",
    "print(f\"Standard Deviation: {hstd:.4f}\")\n",
    "\n",
    "print(f\"wind speed of Day data\")\n",
    "print(f\"Mean: {dmean:.4f}\")\n",
    "print(f\"Median: {dmedian:.4f}\")\n",
    "print(f\"Standard Deviation: {dstd:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dHaYtuP4C78"
   },
   "source": [
    "## Q13. Identify any potential outliers in a numerical column of your choice. Explain your approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "id": "nVkU-okb4EiU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 342 outliers in windspeed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hour_data = pd.read_csv(\"C:\\\\Users\\\\AKHIL\\\\ICT DSA\\\\bike+sharing+dataset\\\\hour.csv\")\n",
    "coloum= 'windspeed'\n",
    "Q1 = hour_data[coloum].quantile(0.25)  \n",
    "Q3 = hour_data[coloum].quantile(0.75) \n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "\n",
    "outliers_iqr = hour_data[(hour_data[coloum] < lower_bound) | (hour_data[coloum] > upper_bound)]\n",
    "print(f\"Found {len(outliers_iqr)} outliers in {coloum}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14sUq8ZF4E88"
   },
   "source": [
    "## Q.14 Find the correlation between numerical columns and discuss any interesting relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "id": "jnAOuuwt4Hmb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix\n",
      "             instant    season        yr      mnth        hr   holiday  \\\n",
      "instant     1.000000  0.404046  0.866014  0.489164 -0.004775  0.014723   \n",
      "season      0.404046  1.000000 -0.010742  0.830386 -0.006117 -0.009585   \n",
      "yr          0.866014 -0.010742  1.000000 -0.010473 -0.003867  0.006692   \n",
      "mnth        0.489164  0.830386 -0.010473  1.000000 -0.005772  0.018430   \n",
      "hr         -0.004775 -0.006117 -0.003867 -0.005772  1.000000  0.000479   \n",
      "holiday     0.014723 -0.009585  0.006692  0.018430  0.000479  1.000000   \n",
      "weekday     0.001357 -0.002335 -0.004485  0.010400 -0.003498 -0.102088   \n",
      "workingday -0.003416  0.013743 -0.002196 -0.003477  0.002285 -0.252471   \n",
      "weathersit -0.014198 -0.014524 -0.019157  0.005400 -0.020203 -0.017036   \n",
      "temp        0.136178  0.312025  0.040913  0.201691  0.137603 -0.027340   \n",
      "atemp       0.137615  0.319380  0.039222  0.208096  0.133750 -0.030973   \n",
      "hum         0.009577  0.150625 -0.083546  0.164411 -0.276498 -0.010588   \n",
      "windspeed  -0.074505 -0.149773 -0.008740 -0.135386  0.137252  0.003988   \n",
      "casual      0.158295  0.120206  0.142779  0.068457  0.301202  0.031564   \n",
      "registered  0.282046  0.174226  0.253684  0.122273  0.374141 -0.047345   \n",
      "cnt         0.278379  0.178056  0.250495  0.120638  0.394071 -0.030927   \n",
      "\n",
      "             weekday  workingday  weathersit      temp     atemp       hum  \\\n",
      "instant     0.001357   -0.003416   -0.014198  0.136178  0.137615  0.009577   \n",
      "season     -0.002335    0.013743   -0.014524  0.312025  0.319380  0.150625   \n",
      "yr         -0.004485   -0.002196   -0.019157  0.040913  0.039222 -0.083546   \n",
      "mnth        0.010400   -0.003477    0.005400  0.201691  0.208096  0.164411   \n",
      "hr         -0.003498    0.002285   -0.020203  0.137603  0.133750 -0.276498   \n",
      "holiday    -0.102088   -0.252471   -0.017036 -0.027340 -0.030973 -0.010588   \n",
      "weekday     1.000000    0.035955    0.003311 -0.001795 -0.008821 -0.037158   \n",
      "workingday  0.035955    1.000000    0.044672  0.055390  0.054667  0.015688   \n",
      "weathersit  0.003311    0.044672    1.000000 -0.102640 -0.105563  0.418130   \n",
      "temp       -0.001795    0.055390   -0.102640  1.000000  0.987672 -0.069881   \n",
      "atemp      -0.008821    0.054667   -0.105563  0.987672  1.000000 -0.051918   \n",
      "hum        -0.037158    0.015688    0.418130 -0.069881 -0.051918  1.000000   \n",
      "windspeed   0.011502   -0.011830    0.026226 -0.023125 -0.062336 -0.290105   \n",
      "casual      0.032721   -0.300942   -0.152628  0.459616  0.454080 -0.347028   \n",
      "registered  0.021578    0.134326   -0.120966  0.335361  0.332559 -0.273933   \n",
      "cnt         0.026900    0.030284   -0.142426  0.404772  0.400929 -0.322911   \n",
      "\n",
      "            windspeed    casual  registered       cnt  \n",
      "instant     -0.074505  0.158295    0.282046  0.278379  \n",
      "season      -0.149773  0.120206    0.174226  0.178056  \n",
      "yr          -0.008740  0.142779    0.253684  0.250495  \n",
      "mnth        -0.135386  0.068457    0.122273  0.120638  \n",
      "hr           0.137252  0.301202    0.374141  0.394071  \n",
      "holiday      0.003988  0.031564   -0.047345 -0.030927  \n",
      "weekday      0.011502  0.032721    0.021578  0.026900  \n",
      "workingday  -0.011830 -0.300942    0.134326  0.030284  \n",
      "weathersit   0.026226 -0.152628   -0.120966 -0.142426  \n",
      "temp        -0.023125  0.459616    0.335361  0.404772  \n",
      "atemp       -0.062336  0.454080    0.332559  0.400929  \n",
      "hum         -0.290105 -0.347028   -0.273933 -0.322911  \n",
      "windspeed    1.000000  0.090287    0.082321  0.093234  \n",
      "casual       0.090287  1.000000    0.506618  0.694564  \n",
      "registered   0.082321  0.506618    1.000000  0.972151  \n",
      "cnt          0.093234  0.694564    0.972151  1.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hour_data = pd.read_csv(\"C:\\\\Users\\\\AKHIL\\\\ICT DSA\\\\bike+sharing+dataset\\\\hour.csv\") \n",
    "\n",
    "matrix = numerical_data.corr()\n",
    "print(\"matrix\")\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ru-xlbd44IAY"
   },
   "source": [
    "## Q.15 Based on your analysis, provide a brief summary of any insights or patterns you discovered in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15NUIdxK4I03"
   },
   "outputs": [],
   "source": [
    "Temperature and Time of Day Impact Bike Rentals\n",
    "Higher temperatures increase bike rentals (correlation = 0.40).\n",
    "Peak usage occurs during morning (8 AM) and evening (5-7 PM) rush hours.\n",
    "Colder months see fewer rentals, indicating seasonal effects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMGro15Q5WhF"
   },
   "source": [
    "## Q.16 In which season (Spring, Summer, Fall, Winter) people rented bikes the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "id": "KhlVV_bK5jxm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seasonal bike rentals:\n",
      "season\n",
      "Fall      1061129\n",
      "Spring     471348\n",
      "Summer     918589\n",
      "Winter     841613\n",
      "Name: cnt, dtype: int64\n",
      "The season with the most rentals is Fall with 1061129 rentals.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hour_data = pd.read_csv(\"C:\\\\Users\\\\AKHIL\\\\ICT DSA\\\\bike+sharing+dataset\\\\hour.csv\")\n",
    "season_mapping = {1: \"Spring\", 2: \"Summer\", 3: \"Fall\", 4: \"Winter\"}\n",
    "hour_data['season'] = data['season'].map(season_mapping)\n",
    "season_rentals = data.groupby('season')['cnt'].sum()\n",
    "most_rented_season = season_rentals.idxmax()\n",
    "most_rented_count = season_rentals.max()\n",
    "print(\"Seasonal bike rentals:\")\n",
    "print(season_rentals)\n",
    "print(f\"The season with the most rentals is {most_rented_season} with {most_rented_count} rentals.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eudb_1Lb5sVc"
   },
   "source": [
    "## Q.17 What is the peak hour in which bike rents the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "id": "p0xSgv8g50yt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['instant', 'dteday', 'season', 'yr', 'mnth', 'hr', 'holiday', 'weekday',\n",
      "       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed',\n",
      "       'casual', 'registered', 'cnt'],\n",
      "      dtype='object')\n",
      "Hourly bike rentals:\n",
      "hr\n",
      "0      39130\n",
      "1      24164\n",
      "2      16352\n",
      "3       8174\n",
      "4       4428\n",
      "5      14261\n",
      "6      55132\n",
      "7     154171\n",
      "8     261001\n",
      "9     159438\n",
      "10    126257\n",
      "11    151320\n",
      "12    184414\n",
      "13    184919\n",
      "14    175652\n",
      "15    183149\n",
      "16    227748\n",
      "17    336860\n",
      "18    309772\n",
      "19    226789\n",
      "20    164550\n",
      "21    125445\n",
      "22     95612\n",
      "23     63941\n",
      "Name: cnt, dtype: int64\n",
      "The peak hour is 17:00 with 336860 rentals.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\AKHIL\\\\ICT DSA\\\\bike+sharing+dataset\\\\hour.csv\")\n",
    "print(data.columns)\n",
    "hourly_rentals = data.groupby('hr')['cnt'].sum() \n",
    "peak_hour = hourly_rentals.idxmax()\n",
    "peak_rentals = hourly_rentals.max()\n",
    "print(\"Hourly bike rentals:\")\n",
    "print(hourly_rentals)\n",
    "print(f\"The peak hour is {peak_hour}:00 with {peak_rentals} rentals.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7rArqGQ6ji4"
   },
   "source": [
    "## Q.18 In which day of a week bikes rents out most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "id": "6GPCbpsx6oYE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bike rentals by day of the week:\n",
      "weekday\n",
      "Friday       487790\n",
      "Thursday     485395\n",
      "Saturday     477807\n",
      "Wednesday    473048\n",
      "Tuesday      469109\n",
      "Monday       455503\n",
      "Sunday       444027\n",
      "Name: cnt, dtype: int64\n",
      "The day with the most rentals is Friday with 487790 rentals.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\AKHIL\\\\ICT DSA\\\\bike+sharing+dataset\\\\hour.csv\")\n",
    "weekday_mapping = {\n",
    "    0: \"Sunday\",\n",
    "    1: \"Monday\",\n",
    "    2: \"Tuesday\",\n",
    "    3: \"Wednesday\",\n",
    "    4: \"Thursday\",\n",
    "    5: \"Friday\",\n",
    "    6: \"Saturday\"\n",
    "}\n",
    "data['weekday'] = data['weekday'].map(weekday_mapping)\n",
    "weekday_rentals = data.groupby('weekday')['cnt'].sum()\n",
    "weekday_rentals = weekday_rentals.sort_values(ascending=False)\n",
    "most_rented_day = weekday_rentals.idxmax()\n",
    "most_rented_count = weekday_rentals.max()\n",
    "\n",
    "print(\"Bike rentals by day of the week:\")\n",
    "print(weekday_rentals)\n",
    "print(f\"The day with the most rentals is {most_rented_day} with {most_rented_count} rentals.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFO_Twk66qw-"
   },
   "source": [
    "## Q.19 In which hour Casual users rents bikes the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59CHoEUt66GR"
   },
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtvgNN-U69rh"
   },
   "source": [
    "## Q.20 What is the maximum temperature observed in each of the seasons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U_NwDHv57tLT"
   },
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
